{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "We begin by loading in necessary software packages, introducing options for saving the results, and software for computing PSIS LOO in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import pystan\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test data (not all data is used for fitting/training)\n",
    "use_testdata = False\n",
    "\n",
    "# create plots of the data\n",
    "show_data = True\n",
    "\n",
    "# netCDF output file (set to None to not save output)\n",
    "savename_output = '../results/zinser_results_window.nc'\n",
    "\n",
    "# save the Stan output instead a few stats (only active if filename is specified above)\n",
    "save_stan_output = True\n",
    "\n",
    "# specify the Stan variable names to save; if set to None, all variables are saved \n",
    "# (only active if save_stan_output is True)\n",
    "varnames_save = None\n",
    "\n",
    "# the number of tries to fit each Stan model to achieve an R-hat < 1.1\n",
    "num_tries = 3\n",
    "\n",
    "# the number of chains to run\n",
    "num_chains = 6\n",
    "\n",
    "# the prior_only option passed to each Stan model\n",
    "prior_only = False\n",
    "\n",
    "# Whether or not to extend the time series two four days by appending the dataset to itself\n",
    "extend = True\n",
    "\n",
    "# Number of days in the full dataset\n",
    "# Maximum 2 if extend is false, maximum 4 if extend is true\n",
    "limit_days = 4\n",
    "\n",
    "# Number of days in each window\n",
    "# Recommend maximum to be half of limit_days\n",
    "limit_days_window = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load processed data\n",
    "datafile = '../data/size_distribution/zinser_processed.nc'\n",
    "\n",
    "dataname = 'zinser'\n",
    "\n",
    "desc = 'Culture dataset'\n",
    "\n",
    "# Indices of data to hold out for hold-out validation\n",
    "# Uncomment desired line and set use_testdata to true\n",
    "itestfile = None\n",
    "# itestfile = '../data/hold_out/keep_twothirds.csv'\n",
    "# itestfile = '../data/hold_out/keep_half.csv'\n",
    "# itestfile = '../data/hold_out/keep_onethird.csv'\n",
    "\n",
    "size_units = 'fg C cell$^{-1}$'\n",
    "\n",
    "\n",
    "def get_data(datafile, size_units, itestfile, dataname, desc, extend=False):\n",
    "    \n",
    "    data_gridded = {}\n",
    "    with nc4.Dataset(datafile) as nc:\n",
    "        for var in nc.variables:\n",
    "            data_gridded[var] = nc.variables[var][:]\n",
    "\n",
    "    # create \"counts\" entry\n",
    "    if 'count' in data_gridded:\n",
    "        data_gridded['counts'] = (data_gridded['count'][None,:]\n",
    "                                  * data_gridded['w_obs']).astype(int)\n",
    "    elif 'abundance' in data_gridded:\n",
    "        logging.warning('Using \"abundance\" data to generate count data for the model.')\n",
    "        data_gridded['counts'] = (data_gridded['count'][None,:]\n",
    "                                  * data_gridded['w_obs']).astype(int)\n",
    "    else:\n",
    "        raise RuntimeError('Cannot find a \"count\" or \"abundance\" entry in \"{}\".'.format(datafile))\n",
    "    \n",
    "    # Appends the time series to itself to create a pseudo four-day dataset\n",
    "    if extend:\n",
    "        data_gridded['time'] = np.concatenate((data_gridded['time'],\n",
    "                                               (data_gridded['time']\n",
    "                                               + data_gridded['time'][-1]\n",
    "                                               + data_gridded['time'][1])[:-1]))\n",
    "        \n",
    "        for item in ('w_obs', 'PAR', 'abundance', 'count', 'counts'):\n",
    "            if len(data_gridded[item].shape) == 2:\n",
    "                data_gridded[item] = np.concatenate((data_gridded[item],\n",
    "                                                     data_gridded[item][:, 1:]), axis=1)\n",
    "            else:\n",
    "                data_gridded[item] = np.concatenate((data_gridded[item],\n",
    "                                                     data_gridded[item][1:]))\n",
    "\n",
    "    # add description\n",
    "    desc += ' (m={data[m]}, $\\Delta_v^{{-1}}$={data[delta_v_inv]})'.format(data=data_gridded)\n",
    "    \n",
    "    return data_gridded, desc\n",
    "\n",
    "data_gridded, desc = get_data(datafile, size_units, itestfile, dataname, desc, extend=extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_colorbar(ax, **cbarargs):\n",
    "    axins_cbar = inset_axes(ax, width='3%', height='90%', loc=5,\n",
    "                            bbox_to_anchor=(0.05,0.0,1,1),\n",
    "                            bbox_transform=ax.transAxes)\n",
    "    mpl.colorbar.ColorbarBase(axins_cbar, orientation='vertical',\n",
    "                              **cbarargs)\n",
    "\n",
    "if show_data:\n",
    "    nrows = 3\n",
    "\n",
    "    v_min = data_gridded['v_min']\n",
    "    delta_v = 1.0/data_gridded['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data_gridded['m'])*delta_v) \n",
    "\n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "\n",
    "    ax = axs[0]\n",
    "    ax.set_title('raw '+desc, size=20)\n",
    "    ax.plot(data_gridded['time'], data_gridded['PAR'], color='gold')\n",
    "    ax.set(ylabel='PAR')\n",
    "\n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data_gridded['time'], v, data_gridded['w_obs'],\n",
    "                       shading='auto')\n",
    "    ax.set(ylabel='size ({})'.format(size_units))\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='size class proportion')\n",
    "\n",
    "    ax = axs[2]\n",
    "    pc = ax.pcolormesh(data_gridded['time'], v, data_gridded['counts'],\n",
    "                       shading='auto')\n",
    "    ax.set(ylabel='size ({})'.format(size_units))\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "axs[-1].set_xlabel=('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Re-plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Stan model\n",
    "def data_prep(data_gridded, dt=20, limit_days=2, start=0, use_testdata=False,\n",
    "              itestfile=None, prior_only=False):\n",
    "    \n",
    "    data = {'dt':dt}\n",
    "    for v in ('m','v_min','delta_v_inv'):\n",
    "        data[v] = data_gridded[v]\n",
    "\n",
    "    data['obs'] = data_gridded['w_obs']\n",
    "    data['t_obs'] = data_gridded['time']\n",
    "    par = data_gridded['PAR']\n",
    "\n",
    "    if limit_days > 0:\n",
    "        limit_minutes = limit_days*1440\n",
    "\n",
    "        ind_obs = (start*60 <= data['t_obs']) & (data['t_obs'] < limit_minutes+start*60)\n",
    "\n",
    "        if not np.all(ind_obs):\n",
    "            total = data['obs'].shape[1]\n",
    "            remove = total - data['obs'][:, ind_obs].shape[1]\n",
    "            print('start is set to {}, limit_days is set to {}, removing {}/{} observation times'.format(start,\n",
    "                                                                                                         limit_days,\n",
    "                                                                                                         remove,\n",
    "                                                                                                         total))\n",
    "\n",
    "        data['t_obs'] = data['t_obs'][ind_obs]\n",
    "        data['obs'] = data['obs'][:,ind_obs]\n",
    "\n",
    "        data['nt'] = int(limit_minutes//data['dt']+1)\n",
    "\n",
    "    data['nt_obs'] = data['t_obs'].size\n",
    "\n",
    "    if use_testdata:\n",
    "        # load cross-validation testing indices and add them to data\n",
    "        data['i_test'] = np.loadtxt(itestfile).astype(int)\n",
    "        # remove last index, so that dimensions agree\n",
    "        data['i_test'] = data['i_test'][:-1]\n",
    "    else:\n",
    "        # set all indices to zero\n",
    "        data['i_test'] = np.zeros(data['nt_obs'], dtype=int)\n",
    "\n",
    "    # switch on or off data fitting\n",
    "    data['prior_only'] = int(prior_only)\n",
    "\n",
    "    # add light data\n",
    "    t = np.arange(data['nt'])*data['dt'] + start*60\n",
    "    data['E'] = np.interp(t, xp=data_gridded['time'][ind_obs], fp=par[ind_obs])\n",
    "\n",
    "    # real count data\n",
    "    data['obs_count'] = data_gridded['counts'][:, ind_obs]\n",
    "    \n",
    "    data['start'] = start\n",
    "\n",
    "    # consistency check\n",
    "    if len(data['i_test']) != data['nt_obs']:\n",
    "        raise ValueError('Invalid number of testing indices (expected {}, got {}).'.format(data['nt_obs'],\n",
    "                                                                                       len(data['i_test'])))\n",
    "    return data\n",
    "\n",
    "\n",
    "data = data_prep(data_gridded, dt=20, limit_days=limit_days, start=0,\n",
    "                 use_testdata=use_testdata, itestfile=itestfile,\n",
    "                 prior_only=prior_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    nrows = 3\n",
    "\n",
    "    v_min = data['v_min']\n",
    "    delta_v = 1.0/data['delta_v_inv']\n",
    "    v = v_min * 2**(np.arange(data['m'])*delta_v) \n",
    "    t = np.arange(data['nt'])*data['dt']\n",
    "\n",
    "\n",
    "    fig,axs = plt.subplots(nrows=nrows, sharex=True, figsize=(12,4*nrows))\n",
    "\n",
    "    ax = axs[0]\n",
    "    ax.set_title('processed '+desc, size=20)\n",
    "    ax.plot(t, data['E'], color='gold')\n",
    "    ax.set(ylabel='E')\n",
    "\n",
    "    ax = axs[1]\n",
    "    pc = ax.pcolormesh(data['t_obs'], v, data['obs'], shading='auto')\n",
    "    ax.set(ylabel='size ({})'.format(size_units))\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap,\n",
    "                 label='size class proportion')\n",
    "    ax.set_xlim(left=0.0)\n",
    "\n",
    "    ax = axs[2]\n",
    "    pc = ax.pcolormesh(data['t_obs'], v, data['obs_count'], shading='auto')\n",
    "    ax.set(ylabel='size ({})'.format(size_units))\n",
    "    add_colorbar(ax, norm=pc.norm, cmap=pc.cmap, label='counts')\n",
    "    ax.set_xlim(left=0.0)\n",
    "axs[-1].set_xlabel('time (minutes)')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose models to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code files\n",
    "stan_files = {\n",
    "    'm_bmx': '../stan_code/m_bmx.stan',\n",
    "    'm_bmb': '../stan_code/m_bmb.stan',\n",
    "    'm_pmb': '../stan_code/m_pmb.stan',\n",
    "    'm_fmb': '../stan_code/m_fmb.stan',\n",
    "    'm_fmf': '../stan_code/m_fmf.stan',\n",
    "    'm_btb': '../stan_code/m_btb.stan',\n",
    "    'm_ptb': '../stan_code/m_ptb.stan',\n",
    "    'm_ftb': '../stan_code/m_ftb.stan',\n",
    "    'm_ftf': '../stan_code/m_ftf.stan',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models to the Data in a rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_rhat(fit):\n",
    "    s = fit.summary()\n",
    "    irhat = s['summary_colnames'].index(\"Rhat\")\n",
    "    return np.nanmax(s['summary'][:,irhat])\n",
    "\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "if 'mcmcs' not in globals():\n",
    "    mcmcs = {}\n",
    "if 'maxrhats' not in globals():\n",
    "    maxrhats = {}\n",
    "if 'sampling_time' not in globals():\n",
    "    sampling_time = {}\n",
    "if 'num_tries' not in globals():\n",
    "    num_tries = 3\n",
    "    \n",
    "try_again = True\n",
    "refit_all = False\n",
    "\n",
    "refit_required = {}\n",
    "stan_base_code = {}\n",
    "for key, stan_file in stan_files.items():\n",
    "    with open(stan_file) as f:\n",
    "        stan_base_code[key] = f.read()\n",
    "\n",
    "stan_code = {}\n",
    "for model in stan_files.keys():\n",
    "    code_split = stan_base_code[model].split('\\n')\n",
    "    stan_code[model] = '\\n'.join(code_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in stan_files.keys():\n",
    "    refit_required[model] = True\n",
    "    if model in models and models[model].model_code == stan_code[model]:\n",
    "        print('{}: unchanged code, not recompiling'.format(model))\n",
    "        refit_required[model] = False\n",
    "    else:\n",
    "        if model in models:\n",
    "            print('{}: code change detected, recompiling'.format(model))\n",
    "        else:\n",
    "            print('{}: compiling'.format(model))\n",
    "        models[model] = pystan.StanModel(model_code=stan_code[model],\n",
    "                                         model_name=model,\n",
    "                                         obfuscate_model_name=False)\n",
    "\n",
    "# Get window slices of data\n",
    "max_start_time = limit_days*24 - limit_days_window*24 + 2\n",
    "windows = np.arange(0, max_start_time+1, 2)  # Start times of each rolling window\n",
    "data = {}\n",
    "for window in windows:\n",
    "    data[window] = data_prep(data_gridded, dt=20, limit_days=limit_days_window, start=window)\n",
    "\n",
    "# run a bunch of experiments -- this may take a while\n",
    "for model in models:\n",
    "    if model not in maxrhats:\n",
    "        maxrhats[model] = {}\n",
    "    if model not in sampling_time:\n",
    "        sampling_time[model] = {}\n",
    "    for window in windows:\n",
    "        if window not in maxrhats[model]:\n",
    "            maxrhats[model][window] = []\n",
    "        if window not in sampling_time[model]:\n",
    "            sampling_time[model][window] = []\n",
    "        if model in mcmcs:\n",
    "            if window in mcmcs[model] and not refit_all and not refit_required[model]:\n",
    "                print('{}: found existing results:'.format(model))\n",
    "                print('{}'.format(model)) \n",
    "                print('\\n'.join(x for x in mcmcs[model][window].__str__().split('\\n') if '[' not in x))\n",
    "                rhat_max = get_max_rhat(mcmcs[model][window])\n",
    "                if try_again and rhat_max >= 1.1:\n",
    "                    print('{}: found Rhat={:.3f}, trying again'.format(model, rhat_max))\n",
    "                else:\n",
    "                    print('{}: not re-running model'.format(model))\n",
    "                    print()\n",
    "                    continue\n",
    "            elif refit_all:\n",
    "                print('{}: refit_all is active, re-running model'.format(model))\n",
    "            elif refit_required[model]:\n",
    "                print('{}: change in model code requires re-running model'.format(model))\n",
    "        else:\n",
    "            mcmcs[model] = {}\n",
    "        for itry in range(num_tries):\n",
    "            t0 = time.time()\n",
    "            mcmcs[model][window] = models[model].sampling(data=data[window], iter=2000, chains=num_chains)\n",
    "            sampling_time[model][window].append(time.time() - t0) # in seconds\n",
    "            # get max Rhat\n",
    "            rhat_max = get_max_rhat(mcmcs[model][window])\n",
    "            maxrhats[model][window].append(rhat_max)\n",
    "            print('{}: in try {}/{} found Rhat={:.3f}'.format(model, itry+1, num_tries, rhat_max), end='')\n",
    "            if rhat_max < 1.1 or itry == num_tries - 1:\n",
    "                print()\n",
    "                break\n",
    "            print(', trying again')\n",
    "        \n",
    "        print('{}'.format(model)) \n",
    "        print('\\n'.join(x for x in mcmcs[model][window].__str__().split('\\n') if '[' not in x))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'varnames_save' not in globals():\n",
    "    varnames_save = None\n",
    "\n",
    "save_only_converged = False\n",
    "\n",
    "if savename_output is not None:\n",
    "    with nc4.Dataset(savename_output, 'w') as nc:\n",
    "        for model in mcmcs:\n",
    "            ncm = nc.createGroup(model)\n",
    "            \n",
    "            # write model description\n",
    "            ncm.setncattr('code', stan_files[model])\n",
    "            \n",
    "            if save_stan_output:\n",
    "                for window in windows:\n",
    "                    if save_only_converged and get_max_rhat(mcmcs[model][window]) > 1.1:\n",
    "                        logging.warning('Model \"{}\" did not converge -- skipping.'.format(model))\n",
    "                        continue\n",
    "                    ncg = ncm.createGroup(str(window))\n",
    "                    dimensions = {\n",
    "                        'obstime':int(data[window]['nt_obs']),\n",
    "                        'time':int(data[window]['nt']),\n",
    "                        'sizeclass':int(data[window]['m']),\n",
    "                        'm_minus_j_plus_1':int(data[window]['m']-data[window]['delta_v_inv']),\n",
    "                        'm_minus_1':int(data[window]['m']-1),\n",
    "                        'knots_minus_1':int(6-1),  # hardcoded, adjust for varying nknots\n",
    "                        'sample': mcmcs[model][window]['mod_obspos'].shape[0],\n",
    "                    }\n",
    "                    dimensions_inv = {v:k for k,v in dimensions.items()}\n",
    "                    \n",
    "                    for d in dimensions:\n",
    "                        ncg.createDimension(d, dimensions[d])\n",
    "                    \n",
    "                    if 'tau[1]' in mcmcs[model][window].flatnames:\n",
    "                        dimensions['tau'] = mcmcs[model][window]['tau'].shape[1]\n",
    "                        dimensions_inv[dimensions['tau']] = 'tau'\n",
    "                        ncg.createDimension('tau', dimensions['tau'])\n",
    "\n",
    "                    ncg.createVariable('time', int, ('time',))\n",
    "                    ncg.variables['time'][:] = int(data[window]['dt']) * np.arange(data[window]['nt'])\n",
    "                    ncg.variables['time'].units = 'minutes since start of experiment'\n",
    "\n",
    "                    ncg.createVariable('obstime', int, ('obstime',))\n",
    "                    ncg.variables['obstime'][:] = data[window]['t_obs'].astype(int)\n",
    "                    ncg.variables['obstime'].units = 'minutes since start of experiment'\n",
    "                    ncg.variables['obstime'].long_name = 'time of observations'\n",
    "\n",
    "                    for v in ('dt', 'm', 'v_min', 'delta_v_inv', 'obs', 'i_test',\n",
    "                              'E', 'obs_count'):\n",
    "                        if isinstance(data[window][v], int):\n",
    "                            ncg.createVariable(v, int, zlib=True)\n",
    "                            ncg.variables[v][:] = data[window][v]\n",
    "                        elif isinstance(data[window][v], float):\n",
    "                            ncg.createVariable(v, float, zlib=True)\n",
    "                            ncg.variables[v][:] = data[window][v]\n",
    "                        else:\n",
    "                            dims = tuple(dimensions_inv[d] for d in data[window][v].shape)\n",
    "                            ncg.createVariable(v, data[window][v].dtype, dims, zlib=True)\n",
    "                            ncg.variables[v][:] = data[window][v]\n",
    "\n",
    "                \n",
    "                    varnames = set(v.split('[')[0] for v in mcmcs[model][window].flatnames)\n",
    "                    if varnames_save is None:\n",
    "                        varnames_curr = varnames\n",
    "                    else:\n",
    "                        varnames_curr = varnames_save\n",
    "\n",
    "                    for v in varnames_curr:\n",
    "                        if v in varnames:\n",
    "                            dims = tuple(dimensions_inv[d]\n",
    "                                         for d in mcmcs[model][window][v].shape)\n",
    "                            ncg.createVariable(v, float, dims, zlib=True)\n",
    "                            ncg.variables[v][:] = mcmcs[model][window][v]\n",
    "                        else:\n",
    "                            logging.warning('Cannot find variable \"{}\" for model \"{}\".'.format(v,\n",
    "                                                                                               model))\n",
    "            else:\n",
    "                for i, window in enumerate(windows):\n",
    "                    if i == 0:\n",
    "                        ncm.createDimension('window', len(mcmcs[model]))\n",
    "                        ncm.createDimension('sample',\n",
    "                                            mcmcs[model][window]['divrate'].shape[0])\n",
    "\n",
    "                        ncm.createVariable('divrate', float, ('window','sample'))\n",
    "                        ncm.createVariable('sumsqdiff', float, ('window','sample'))\n",
    "                        ncm.variables['sumsqdiff'].setncattr('long_name',\n",
    "                                                             'sum of squared column differences')\n",
    "\n",
    "                    ncm.variables['divrate'][i,:] = mcmcs[model][window]['divrate']\n",
    "\n",
    "                    obs = data[window]['obs']\n",
    "\n",
    "                    tmp = mcmcs[model][window]['mod_obspos']\n",
    "                    tmp/= np.sum(tmp, axis=1)[:, None, :]\n",
    "                    tmp -= obs[None, :, :]\n",
    "                    tmp **= 2\n",
    "\n",
    "                    if np.all(data[window]['i_test'] == 0):\n",
    "                        ncm.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp, axis=1),\n",
    "                                                                  axis=1)\n",
    "                        if i == 0:\n",
    "                            ncm.variables['sumsqdiff'].setncattr('data_used',\n",
    "                                                                 'all data')\n",
    "                    else:\n",
    "                        nc.variables['sumsqdiff'][i,:] = np.mean(np.sum(tmp[:, :, data[window]['i_test'] == 1],\n",
    "                                                                        axis=1), axis=1)\n",
    "                        if i == 0:\n",
    "                            ncm.variables['sumsqdiff'].setncattr('data_used', 'testing data')\n",
    "\n",
    "                    for iv,v in enumerate(('gamma_max', 'rho_max', 'xi',\n",
    "                                           'xir', 'E_star')):\n",
    "                        if i == 0:\n",
    "                            ncm.createVariable(v, float, ('model','sample'))\n",
    "                        if v in mcmcs[model][window].flatnames:\n",
    "                            ncm.variables[v][i,:] = mcmcs[model][window][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
